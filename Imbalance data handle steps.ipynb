{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:18:35.860339Z",
     "start_time": "2018-10-03T11:18:35.848344Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balance</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  balance  var1  var2  var3  var4\n",
       "0       B     1     1     1     1\n",
       "1       R     1     1     1     2\n",
       "2       R     1     1     1     3\n",
       "3       R     1     1     1     4\n",
       "4       R     1     1     1     5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "# Read dataset\n",
    "df = pd.read_csv('balance-scale.data', names=['balance', 'var1', 'var2', 'var3', 'var4'])\n",
    " \n",
    "# Display example observations\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:20:25.940783Z",
     "start_time": "2018-10-03T11:20:25.925824Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R    288\n",
       "L    288\n",
       "B     49\n",
       "Name: balance, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['balance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:20:58.357117Z",
     "start_time": "2018-10-03T11:20:58.342158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    576\n",
       "1     49\n",
       "Name: balance, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform into binary classification\n",
    "df['balance'] = [1 if b=='B' else 0 for b in df.balance]\n",
    " \n",
    "df['balance'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, only about 8% of the observations were balanced. Therefore, if we were to always predict 0, we'd achieve an accuracy of 92%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:21:44.619955Z",
     "start_time": "2018-10-03T11:21:42.857608Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:22:31.557936Z",
     "start_time": "2018-10-03T11:22:31.451065Z"
    }
   },
   "outputs": [],
   "source": [
    "#Train model on imbalanced data\n",
    "# Separate input features (X) and target variable (y)\n",
    "y = df.balance\n",
    "X = df.drop('balance', axis=1)\n",
    " \n",
    "# Train model\n",
    "clf_0 = LogisticRegression().fit(X, y)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_0 = clf_0.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:22:47.230739Z",
     "start_time": "2018-10-03T11:22:47.219769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9216\n"
     ]
    }
   ],
   "source": [
    "# How's the accuracy?\n",
    "print( accuracy_score(pred_y_0, y) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our model has 92% overall accuracy, but is it because it's predicting only 1 class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:23:26.288874Z",
     "start_time": "2018-10-03T11:23:26.283888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Should we be excited?\n",
    "print( np.unique( pred_y_0 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this model is only predicting 0, which means it's completely ignoring the minority class in favor of the majority class.\n",
    "\n",
    "Next, we'll look at the first technique for handling imbalanced classes: up-sampling the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Up-sample Minority Class\n",
    "\n",
    "Up-sampling is the process of randomly duplicating observations from the minority class in order to reinforce its signal.\n",
    "\n",
    "There are several heuristics for doing so, but the most common way is to simply resample with replacement.\n",
    "\n",
    "First, we'll import the resampling module from Scikit-Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:24:59.590745Z",
     "start_time": "2018-10-03T11:24:59.586757Z"
    }
   },
   "outputs": [],
   "source": [
    "#Module for resampling\n",
    "\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a new DataFrame with an up-sampled minority class. Here are the steps:\n",
    "\n",
    "1. First, we'll separate observations from each class into different DataFrames.\n",
    "2. Next, we'll resample the minority class with replacement, setting the number of samples to match that of the majority class.\n",
    "3. Finally, we'll combine the up-sampled minority class DataFrame with the original majority class DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:27:29.474976Z",
     "start_time": "2018-10-03T11:27:29.463226Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    576\n",
       "0    576\n",
       "Name: balance, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = df[df.balance==0]\n",
    "df_minority = df[df.balance==1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=576,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "df_upsampled.balance.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the new DataFrame has more observations than the original, and the ratio of the two classes is now 1:1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train another model using Logistic Regression, this time on the balanced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:40:28.600272Z",
     "start_time": "2018-10-03T11:40:28.589208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "0.5138888888888888\n"
     ]
    }
   ],
   "source": [
    "#Train model on upsampled dataset\n",
    "\n",
    "\n",
    "# Separate input features (X) and target variable (y)\n",
    "y = df_upsampled.balance\n",
    "X = df_upsampled.drop('balance', axis=1)\n",
    " \n",
    "# Train model\n",
    "clf_1 = LogisticRegression().fit(X, y)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_1 = clf_1.predict(X)\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "print( np.unique( pred_y_1 ) )\n",
    "# [0 1]\n",
    " \n",
    "# How's our accuracy?\n",
    "print( accuracy_score(y, pred_y_1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Down-sample Majority Class\n",
    "\n",
    "Down-sampling involves randomly removing observations from the majority class to prevent its signal from dominating the learning algorithm.\n",
    "\n",
    "The most common heuristic for doing so is resampling without replacement.\n",
    "\n",
    "The process is similar to that of up-sampling. Here are the steps:\n",
    "1. First, we'll separate observations from each class into different DataFrames.\n",
    "2. Next, we'll resample the majority class without replacement, setting the number of samples to match that of the minority class.\n",
    "3. Finally, we'll combine the down-sampled majority class DataFrame with the original minority class DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:42:06.354178Z",
     "start_time": "2018-10-03T11:42:06.337799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    49\n",
       "0    49\n",
       "Name: balance, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsample majority class\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df.balance==0]\n",
    "df_minority = df[df.balance==1]\n",
    " \n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=49,     # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    " \n",
    "# Display new class counts\n",
    "df_downsampled.balance.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, the new DataFrame has fewer observations than the original, and the ratio of the two classes is now 1:1.\n",
    "\n",
    "Again, let's train a model using Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:42:42.316640Z",
     "start_time": "2018-10-03T11:42:42.308605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "0.5816326530612245\n"
     ]
    }
   ],
   "source": [
    "# Train model on downsampled dataset\n",
    "\n",
    "# Separate input features (X) and target variable (y)\n",
    "y = df_downsampled.balance\n",
    "X = df_downsampled.drop('balance', axis=1)\n",
    " \n",
    "# Train model\n",
    "clf_2 = LogisticRegression().fit(X, y)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_2 = clf_2.predict(X)\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "print( np.unique( pred_y_2 ) )\n",
    "# [0 1]\n",
    " \n",
    "# How's our accuracy?\n",
    "print( accuracy_score(y, pred_y_2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model isn't predicting just one class, and the accuracy seems higher.\n",
    "\n",
    "We'd still want to validate the model on an unseen test dataset, but the results are more encouraging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Change Your Performance Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:44:15.307720Z",
     "start_time": "2018-10-03T11:44:15.303731Z"
    }
   },
   "outputs": [],
   "source": [
    "#Area Under ROC Curve\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:44:40.379412Z",
     "start_time": "2018-10-03T11:44:40.373965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4541919722647962,\n",
       " 0.4820596221328388,\n",
       " 0.46862327066392495,\n",
       " 0.4786837883268913,\n",
       " 0.5814385682015971]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get class probabilities\n",
    "\n",
    "# Predict class probabilities\n",
    "prob_y_2 = clf_2.predict_proba(X)\n",
    " \n",
    "# Keep only the positive class\n",
    "prob_y_2 = [p[1] for p in prob_y_2]\n",
    " \n",
    "prob_y_2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:44:55.328537Z",
     "start_time": "2018-10-03T11:44:55.317676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5680966264056644\n"
     ]
    }
   ],
   "source": [
    "print( roc_auc_score(y, prob_y_2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok... and how does this compare to the original model trained on the imbalanced dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:45:32.093873Z",
     "start_time": "2018-10-03T11:45:32.087862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47480216576426487\n"
     ]
    }
   ],
   "source": [
    "# AUROC of model trained on imbalanced dataset\n",
    "\n",
    "prob_y_0 = clf_0.predict_proba(X)\n",
    "prob_y_0 = [p[1] for p in prob_y_0]\n",
    " \n",
    "print( roc_auc_score(y, prob_y_0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, our original model trained on the imbalanced dataset had an accuracy of 92%, which is much higher than the 58% accuracy of the model trained on the down-sampled dataset.\n",
    "\n",
    "However, the latter model has an AUROC of 57%, which is higher than the 53% of the original model (but not by much).\n",
    "\n",
    "**Note:** if you got an AUROC of 0.47, it just means you need to invert the predictions because Scikit-Learn is misinterpreting the positive class. AUROC should be >= 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Penalize Algorithms (Cost-Sensitive Training)\n",
    "\n",
    "The next tactic is to use penalized learning algorithms that increase the cost of classification mistakes on the minority class.\n",
    "\n",
    "A popular algorithm for this technique is **Penalized-SVM:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:48:52.489150Z",
     "start_time": "2018-10-03T11:48:52.485161Z"
    }
   },
   "outputs": [],
   "source": [
    "#Support Vector Machine\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, we can use the argument **class_weight='balanced'**  to penalize mistakes on the minority class by an amount proportional to how under-represented it is.\n",
    "\n",
    "We also want to include the argument **probability=True** if we want to enable probability estimates for SVM algorithms.\n",
    "\n",
    "Let's train a model using Penalized-SVM on the original imbalanced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:50:47.385722Z",
     "start_time": "2018-10-03T11:50:47.236674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "#Train Penalized SVM on imbalanced dataset\n",
    "\n",
    "# Separate input features (X) and target variable (y)\n",
    "y = df.balance\n",
    "X = df.drop('balance', axis=1)\n",
    " \n",
    "# Train model\n",
    "clf_3 = SVC(kernel='linear', \n",
    "            class_weight='balanced', # penalize\n",
    "            probability=True)\n",
    " \n",
    "clf_3.fit(X, y)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_3 = clf_3.predict(X)\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "print( np.unique( pred_y_3 ) )\n",
    "# [0 1]\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:50:53.590519Z",
     "start_time": "2018-10-03T11:50:53.585533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.688\n"
     ]
    }
   ],
   "source": [
    "# How's our accuracy?\n",
    "print( accuracy_score(y, pred_y_3) )\n",
    "# 0.688\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:50:55.822968Z",
     "start_time": "2018-10-03T11:50:55.812758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46947633219954643\n"
     ]
    }
   ],
   "source": [
    "# What about AUROC?\n",
    "prob_y_3 = clf_3.predict_proba(X)\n",
    "prob_y_3 = [p[1] for p in prob_y_3]\n",
    "print( roc_auc_score(y, prob_y_3) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Use Tree-Based Algorithms\n",
    "\n",
    "The final tactic we'll consider is using tree-based algorithms. Decision trees often perform well on imbalanced datasets because their hierarchical structure allows them to learn signals from both classes.\n",
    "\n",
    "In modern applied machine learning, tree ensembles (Random Forests, Gradient Boosted Trees, etc.) almost always outperform singular decision trees, so we'll jump right into those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:52:05.324779Z",
     "start_time": "2018-10-03T11:52:05.150395Z"
    }
   },
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train a model using a Random Forest on the original imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:53:09.007227Z",
     "start_time": "2018-10-03T11:53:08.977789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest on imbalanced dataset\n",
    "\n",
    "# Separate input features (X) and target variable (y)\n",
    "y = df.balance\n",
    "X = df.drop('balance', axis=1)\n",
    " \n",
    "# Train model\n",
    "clf_4 = RandomForestClassifier()\n",
    "clf_4.fit(X, y)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_4 = clf_4.predict(X)\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "print( np.unique( pred_y_4 ) )\n",
    "# [0 1]\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:53:14.627788Z",
     "start_time": "2018-10-03T11:53:14.622803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9776\n"
     ]
    }
   ],
   "source": [
    "# How's our accuracy?\n",
    "print( accuracy_score(y, pred_y_4) )\n",
    "# 0.9744\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T11:53:17.150741Z",
     "start_time": "2018-10-03T11:53:17.142047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9990079365079365\n"
     ]
    }
   ],
   "source": [
    "# What about AUROC?\n",
    "prob_y_4 = clf_4.predict_proba(X)\n",
    "prob_y_4 = [p[1] for p in prob_y_4]\n",
    "print( roc_auc_score(y, prob_y_4) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! 97% accuracy and nearly 100% AUROC? Is this magic? A sleight of hand? Cheating? Too good to be true?\n",
    "\n",
    "Well, tree ensembles have become very popular because they perform extremely well on many real-world problems. We certainly recommend them wholeheartedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
